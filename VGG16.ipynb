{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTdSfeOvwBXtLp7+px0cDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnan119/neural-network-architectures-in-pytorch/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbMkPlapf4JL"
      },
      "source": [
        "# **VGG16 in PyTorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cgDEiCbfzo-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn # neural networks modules\n",
        "import torch.optim as optim # all optimization algorithms\n",
        "import torch.nn.functional as F # functional module for non-parametric operations\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3UCZ4zchWWy"
      },
      "source": [
        "In PyTorch you define your Models as subclasses of torch.nn.Module.\n",
        "\n",
        "* In the __init__ function, you are supposed to initialize the layers you want to use. Unlike keras, Pytorch goes more low level and you have to specify the sizes of your network so that everything matches.\n",
        "\n",
        "* In the forward method, you specify the connections of your layers. This means that you will use the layers you already initialized, in order to re-use the same layer for each forward pass of data you make.\n",
        "\n",
        "* torch.nn.Functional contains some useful functions like activation functions a convolution operations you can use. However, these are not full layers so if you want to specify a layer of any kind you should use torch.nn.Module.\n",
        "\n",
        "* You would use the torch.nn.Functional conv operations to define a custom layer for example with a convolution operation, but not to define a standard convolution layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4YMOCkhXy8"
      },
      "source": [
        "# vgg architecture\n",
        "VGG16 = [64,\n",
        "         64,\n",
        "         'MAX',\n",
        "         128,\n",
        "         128,\n",
        "         'MAX',\n",
        "         256,\n",
        "         256,\n",
        "         256,\n",
        "         'MAX',\n",
        "         512,\n",
        "         512,\n",
        "         512,\n",
        "         'MAX',\n",
        "         512,\n",
        "         512,\n",
        "         512,\n",
        "         'MAX'] #Then flatten and 4096x4096x1000 add linear layers\n",
        "         \n",
        "# kernel_size = 3x3\n",
        "# padding = 1\n",
        "# stride = 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNwVjhWkTQl"
      },
      "source": [
        "class vgg16_net(nn.Module):\n",
        "  \n",
        "  def __init__(self, in_channels = 3, num_classes = 1000):\n",
        "    super(vgg16_net,self).__init__() # <--- init of the parent method\n",
        "    self.in_channels = in_channels\n",
        "    self.conv_layers = self.create_conv_layers(VGG16)\n",
        "\n",
        "    self.fcs = nn.Sequential(\n",
        "        nn.Linear(512*7*7,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layers(x)\n",
        "    x = x.reshape(x.shape[0],-1)\n",
        "    x = self.fcs(x)\n",
        "    return x\n",
        "\n",
        "  def create_conv_layers(self, architecture):\n",
        "    layers = []\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for x in architecture:\n",
        "      if type(x) == int:\n",
        "        out_channels = x\n",
        "\n",
        "        layers +=  [nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
        "                              kernel_size = (3,3), padding = (1,1), stride = (1,1)),\n",
        "                              nn.BatchNorm2d(x), #NOTE: batch-norm not included in the original implementation\n",
        "                              nn.ReLU()]\n",
        "        in_channels = x\n",
        "      \n",
        "      elif x == 'MAX':\n",
        "        layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
        "\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSyCNgJfmgG4",
        "outputId": "918b26cf-fffe-4c2b-da44-ef735aa69002"
      },
      "source": [
        "model = vgg16_net(in_channels=3, num_classes=1000)\n",
        "x = torch.randn(1,3,224,224)\n",
        "print(model(x).shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknS7QFQnD5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}